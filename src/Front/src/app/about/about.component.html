<div class="container1">
    <div class="row ">
      <div class="col-sm-4 ">
        <div id="list-example" class="list-group">
          <a class="list-group-item list-group-item-action" href="about#list-item1"><strong>#1 Choose Data Ratio</strong></a>
          <a class="list-group-item list-group-item-action" href="about#list-item2"><strong>#2 Set All Hyperparameters</strong> </a>
          <a class="list-group-item list-group-item-action" href="about#list-item3"><strong>#3 Choose Network Layers</strong></a>
          <a class="list-group-item list-group-item-action" href="about#list-item4"><strong>#4 Start Training!</strong></a>
          <a class="list-group-item list-group-item-action" href="about#list-item5"><strong>History of neural networks</strong></a>
        </div>
      </div>
      
      <div id="glavno" class="col-sm-8 ">
        <div data-bs-spy="scroll" data-bs-target="#list-example" data-bs-offset="0" class="scrollspy-example" tabindex="0">
          <div>
            <h1 class="display-1">Let's start!</h1>
            <p class="main-par">
              Are you ready for your journey with neural networks? Get ready, because we are gonna teach you everything you need to know about the basics of Neural Networks! When you finish reading this article, you'll be able to train your first network, and make predictions with it.
              <img class="round mx-auto d-block img-fluid" src="assets/images/steps.png">
            </p>
            <!--<p class=" h4 font-weight-bold">
              Neural networks reflect the behavior of the human brain, allowing computer programs 
              to recognize patterns and solve common problems in the fields of AI, machine learning,
              and deep learning.
            </p>-->
          </div>
          
          <h3 id="list-item1"class="display-5 text-center">Choose Ratio For the Data</h3>
          <div class="stepsDiv">
            <p class="main-par">
              What does this mean? It means that you choose the percentage of the data that network will not see. For instance, if you set ratio to 20%, the network will learn from 
              only 80% of the remaining data, and you will see it's performance exactly on the 20% of the data that you've chosen.
            </p>
            <p>
              This is very important, because if you choose to big training set, model will <span style="font-weight:bold; font-style: italic;">overfit</span>, and it will
              not performe very good on data it has never seen before. On the contrary, if you choose too small training set, model can <span style="font-weight:bold; font-style: italic;">underfit</span>,
              because you didn't provide enough data for it to learn properly.
            </p>
          </div>
          <!--<p class="text-justify font-weight-normal">
            Neural networks, also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), are a subset of machine learning and are at the heart of deep learning algorithms. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another.
          </p>
          <p class="text-justify font-weight-normal">
            Artificial neural networks (ANNs) are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer. Each node, or artificial neuron, connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.
            Visual diagram of an input layer, hidden layers, and an output layer of a feedforward neural network.
          </p>
          <img class="round mx-auto d-block img-fluid" src="assets/images/slika2.jpeg">
          
          <p class="text-justify font-weight-normal">
            Neural networkss rely on training data to learn and improve their accuracy over time. However, once these learning algorithms are fine-tuned for accuracy, they are powerful tools in computer science and artificial intelligence, allowing us to classify and cluster data at a high velocity. Tasks in speech recognition or image recognition can take minutes versus hours when compared to the manual identification by human experts. One of the most well-known neural networks is Google’s search algorithm.
          </p>
          <hr>
          -->

          <h3 id="list-item2"class="display-5 text-center">Set Hyperparameters</h3>
          <div class="stepsDiv">
            <p class="main-par">
              This is the most important step. Hyperparameters decide how will your model be structured - and it directly impacts it's performance.
              There are multiple hyperparameters that can be set by user, and we're gonna go through them all.
            </p>
            <ul>
              <li><span style="font-weight:bold;">Number of epochs</span> This is basically the number of times the network is shown the whole data while training. Epochs can be increased until validation accuracy starts to drop even when overfitting </li>
              <li><span style="font-weight:bold;">Learning rate</span> It defines how rapidly the parameters in a network are updated. Low learning rates lead to smooth coverges, while larger learning rates may not lead to convergence. </li>
              <li><span style="font-weight:bold;">Activation function</span> These are used to introduce non-linearity to models. It is necessary to allow deep learning models to learn nonlinear prediction boundaries. </li>
              <li><span style="font-weight:bold;">Batch size</span> It is the number of subsamples given to the network before which parameter updates occur. If not set, the default batch size is 32. </li>
              <li><span style="font-weight:bold;">Regularization</span> Different regularizers use specific techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting. Our site offers L1 and L2 regularizers. For further info how there regularizers work, visit next <a target="_blank" href="https://neptune.ai/blog/fighting-overfitting-with-l1-or-l2-regularization" style="font-style:italic;">link</a>. </li>
              <li><span style="font-weight:bold;">Problem type</span> There are two types of problems that you can introduce to your model, according to data and the value you want to predict. Regressional problems are ones that predict a regressional value, such as the price of a particular house, someones salary, height etcetera. Second type of problem is classification, which can be binary prediction or multi class prediction. Examples for this are gender, presence of disease and so on. </li>
              <li><span style="font-weight:bold;">Encoding</span> When you introduce data to your model to be trained on, all data needs to be in number format for best predictions. So, if you have string values, such as name, surname, street name you need to encode it to number value. There are few options that are offered on our site (but there are much more possibilities, for further info visit <a target="_blank" href="https://medium.com/analytics-vidhya/categorical-variable-encoding-techniques-17e607fe42f9" style="font-style:italic;">link</a>). </li>
              <li><span style="font-weight:bold;">Randomization</span> When the data is being split into train, validation and test sets, you can split data in certain order, of shuffle data. </li>
            </ul>
          </div>
          <!--
          <p class="text-justify font-weight-normal">
            Think of each individual node as its own linear regression model, composed of input data, weights, a bias (or threshold), and an output. The formula would look something like this:
          </p>
          <img class="round mx-auto d-block img-fluid" src="assets/images/slika3.JPG">
          <p class="text-justify font-weight-normal">
            ∑wixi + bias = w1x1 + w2x2 + w3x3 + bias
          </p>
          <img class="round mx-auto d-block img-fluid" src="assets/images/slika4.JPG">
          <p class="text-justify font-weight-normal">
            output = f(x) = 1 if ∑w1x1 + b>= 0; 0 if ∑w1x1 + b < 0
          </p>
          <p class="text-justify font-weight-normal">
            Once an input layer is determined, weights are assigned. These weights help determine the importance of any given variable, with larger ones contributing more significantly to the output compared to other inputs. All inputs are then multiplied by their respective weights and then summed. Afterward, the output is passed through an activation function, which determines the output. If that output exceeds a given threshold, it “fires” (or activates) the node, passing data to the next layer in the network. This results in the output of one node becoming in the input of the next node. This process of passing data from one layer to the next layer defines this neural network as a feedforward network.
          </p>
          <p class="text-justify font-weight-normal">
            Let’s break down what one single node might look like using binary values. We can apply this concept to a more tangible example, like whether you should go surfing (Yes: 1, No: 0). The decision to go or not to go is our predicted outcome, or y-hat. Let’s assume that there are three factors influencing your decision-making:
          </p>
            <ul>
              <li >Are the waves good? (Yes: 1, No: 0)</li>
              <li >Is the line-up empty? (Yes: 1, No: 0)</li>
              <li >Has there been a recent shark attack? (Yes: 0, No: 1)</li>
            </ul>
          <p class="text-justify font-weight-normal">
            Then, let’s assume the following, giving us the following inputs:
          </p>
          <ul>
            <li>X1 = 1, since the waves are pumping</li>
            <li>X2 = 0, since the crowds are out</li>
            <li>X3 = 1, since there hasn’t been a recent shark attack</li>
          </ul>
          <p class="text-justify font-weight-normal">
            Now, we need to assign some weights to determine importance. Larger weights signify that particular variables are of greater importance to the decision or outcome.
          </p>
          <ul>
            <li>W1 = 5, since large swells don’t come around often</li>
            <li>W2 = 2, since you’re used to the crowds</li>
            <li>W3 = 4, since you have a fear of sharks</li>
          </ul>
          <p class="text-justify font-weight-normal">
            Finally, we’ll also assume a threshold value of 3, which would translate to a bias value of –3. With all the various inputs, we can start to plug in values into the formula to get the desired output.
          </p>
          <p class="text-justify font-weight-normal">
            Y-hat = (1*5) + (0*2) + (1*4) – 3 = 6
          </p>
          <hr>
          -->
          
  
          <h3 id="list-item3"class="display-5 text-center">Neural Network Layers</h3>
          <div class="stepsDiv">
            <p class="main-par">
              Now, you need to choose number of layers of your model, and number of neurons that each one of them will contain. 
            </p>
            <p>
              These are the layers that come between the input and output layers. <br>
              <span class="span-italic-bold">Input layer</span> is the one accepting plain data as input, and the <span class="span-italic-bold">output layer</span> is the one capturing inputs from hidden layer before itself, performs the calculations via its neurons and then the output is computed. The presence of more hidden layers normally improves accuracy to a degree that can 
              change depending on the problem.
              Each one of hidden layers that you add can have different number of neurons, and separate activation functions. This gives you flexibility for more specified construction of the network.
            </p>
          </div>
          <!--
          <p class="text-justify font-weight-normal">
            Neural networks can be classified into different types, which are used for different purposes. While this isn’t a comprehensive list of types, the below would be representative of the most common types of neural networks that you’ll come across for its common use cases:
          </p>
          <p class="text-justify font-weight-normal">
            The perceptron is the oldest neural network, created by Frank Rosenblatt in 1958. It has a single neuron and is the simplest form of a neural network:
          </p>
          <img class="round mx-auto d-block img-fluid" src="assets/images/slika5.JPG">
          <p class="text-justify font-weight-normal">
            Feedforward neural networks, or multi-layer perceptrons (MLPs), are what we’ve primarily been focusing on within this article. They are comprised of an input layer, a hidden layer or layers, and an output layer. While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonlinear. Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.
          </p>
          <p class="text-justify font-weight-normal">
            Convolutional neural networks (CNNs) are similar to feedforward networks, but they’re usually utilized for image recognition, pattern recognition, and/or computer vision. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.
          </p>
          <p class="text-justify font-weight-normal">
            Recurrent neural networks (RNNs) are identified by their feedback loops. These learning algorithms are primarily leveraged when using time-series data to make predictions about future outcomes, such as stock market predictions or sales forecasting.
          </p>
          <hr>
          -->
  
          <h3 id="list-item4"class="display-5 text-center">Training Process</h3>
          <div class="stepsDiv">
            <p class="main-par">
              Now comes the <span class="span-italic-bold">fun part</span> - training and testing the model you've just made!
            </p>
            <p>
              When the model is done training on the data you've provided, you can see multiple metrics that evaluate the success of the data predictions. How does the model know it's own success?<br>
              It's because you've chosen ratio for the data split - training, validation and test sets. The metrics that you see on the graph are from validation set. It is not enough for data to learn and adapt to train set - it needs to have good metrics on validation set too.<br>
              This evaluation is shown through multiple metrics, like loss, accuracy, precision... This actually helps you to tune hyperparameters and find the model with best evaluation metrics.
              <br>
              Now it's getting interesting!
              <br>
              You can use test sample of data to provide final evaluation of your model. 
              <!-- DORADITI -->
            </p>
          </div>
          <!--
          <p class="text-justify font-weight-normal">
            Deep Learning and neural networks tend to be used interchangeably in conversation, which can be confusing. As a result, it’s worth noting that the “deep” in deep learning is just referring to the depth of layers in a neural network. A neural network that consists of more than three layers—which would be inclusive of the inputs and the output—can be considered a deep learning algorithm. A neural network that only has two or three layers is just a basic neural network.
          </p>
          <p class="text-justify font-weight-normal">
            To learn more about the differences between neural networks and other forms of artificial intelligence,  like machine learning, please read the blog post “AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?”
          </p>
          <hr>
          -->

          <h3  id="list-item5"class="display-5 text-center">History of neural network</h3>
          <div class="stepsDiv">
            <p class="main-par">
              The history of neural networks is longer than most people think. While the idea of “a machine that thinks” can be traced to the Ancient Greeks, we’ll focus on the key events that led to the evolution of thinking around neural networks, which has ebbed and flowed in popularity over the years:
            </p>
            <p>
              <strong class="text-decoration-underline">1943:</strong> Warren S. McCulloch and Walter Pitts published “A logical calculus of the ideas immanent in nervous activity (PDF, 1 MB) (link resides outside IBM)” This research sought to understand how the human brain could produce complex patterns through connected brain cells, or neurons. One of the main ideas that came out of this work was the comparison of neurons with a binary threshold to Boolean logic (i.e., 0/1 or true/false statements).   
            </p>
            <p>
             <strong class="text-decoration-underline"> 1958:</strong> Frank Rosenblatt is credited with the development of the perceptron, documented in his research, “The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain” (PDF, 1.6 MB) (link resides outside IBM). He takes McCulloch and Pitt’s work a step further by introducing weights to the equation. Leveraging an IBM 704, Rosenblatt was able to get a computer to learn how to distinguish cards marked on the left vs. cards marked on the right.
            </p>
            <p>
              <strong class="text-decoration-underline">1974:</strong> While numerous researchers contributed to the idea of backpropagation, Paul Werbos was the first person in the US to note its application within neural networks within his PhD thesis (PDF, 8.1 MB) (link resides outside IBM).
            </p>
            <p>
              <strong class="text-decoration-underline">1989:</strong> LeCun published a paper (PDF, 5.7 MB) (link resides outside IBM) illustrating how the use of constraints in backpropagation and its integration into the neural network architecture can be used to train algorithms. This research successfully leveraged a neural network to recognize hand-written zip code digits provided by the U.S. Postal Service.
            </p>
<!--
            <iframe width="100%" height="315" src="https://www.youtube.com/embed/aircAruvnKk"
              title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
              allowfullscreen>
            </iframe>
-->
            <p class="main-par">
              You've come to the end of this brief tutorial! If you still don't understand the use and architecture of Neural Networks, watch this short video.
              <!--Now that you've come to the end of this short tutorial, watch this video to fully understand use of Neural Networks and their potential. -->
            </p>
            <video title="What are neural networks?" frameborder="0" controls
            poster="assets/images/whatareann_placeholder.jpg">
              <source src="assets/videos/whatarenn.mp4">
            </video>
          </div>          
        </div>
      </div>

    </div>
  </div>